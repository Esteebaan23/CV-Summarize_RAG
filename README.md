# ğŸ“„ CV Summarizer & Q&A (RAG) â€” PDF Chatbot with LangChain + FAISS + Watsonx

This project is a **Retrieval-Augmented Generation (RAG)** application that allows users to **upload a PDF (e.g., a resume/CV)** and instantly:

âœ… Generate an **automatic summary** of the candidate as soon as the PDF is uploaded  
âœ… Ask questions about the document and receive **grounded answers** based on the PDF content  
âœ… Easily adapt the same pipeline to summarize and query **other private company documents** (reports, policies, manuals, SOPs, etc.)

Built with:
- **Gradio** (UI)
- **LangChain** (RAG pipeline utilities)
- **FAISS** (vector store for fast similarity search)
- **IBM watsonx.ai** (LLM + embeddings)

---

## ğŸš€ Features

- **Auto-summary on upload** (no button required)
- **Regenerate summary** button (re-run summarization anytime)
- **PDF Q&A chatbot** powered by RAG (retrieval + LLM generation)
- **Session-safe scaling** using `gr.State()` (no global variables â†’ supports multiple users safely)
- Uses **FAISS indexing per session** for fast retrieval during Q&A

---

## ğŸ§  How It Works (RAG Flow)

1. User uploads a **PDF**
2. The app extracts text from the PDF
3. The text is split into chunks using `RecursiveCharacterTextSplitter`
4. Chunks are embedded using **IBM Slate embeddings**
5. Embeddings are stored in **FAISS**
6. For each question:
   - Retrieve top-k relevant chunks
   - Answer using **Watsonx LLM** with the retrieved context

---

## ğŸ“ Project Structure
â”œâ”€â”€ app.py # Main Gradio app
â””â”€â”€ README.md # Documentation



